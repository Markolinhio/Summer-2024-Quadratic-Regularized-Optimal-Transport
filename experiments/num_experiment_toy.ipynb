{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import ot\n",
    "from scipy.special import factorial, gamma\n",
    "\n",
    "import cv2\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "plt.rcParams[\"legend.fontsize\"] = 14\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 7.0\n",
    "plt.rcParams[\"xtick.minor.size\"] = 5.0\n",
    "plt.rcParams[\"ytick.major.size\"] = 7.0\n",
    "plt.rcParams[\"ytick.minor.size\"] = 5.0\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.5\n",
    "plt.rcParams[\"legend.handlelength\"] = 2.0\n",
    "minor_locator = AutoMinorLocator(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical experiment trên CIFAR10, đặt hypothesis, thí nghiệm, và ghi lại kết quả trên Overleaf\n",
    "- **Xử Lý Trước Hình Ảnh**:\n",
    "    - **Original Image**: Bắt đầu với các hình ảnh CIFAR-10, mỗi ảnh có kích thước $32 \\times 32 \\times 3$ (định dạng RGB).\n",
    "    - **Grayscale Conversion**: Chuyển đổi các hình ảnh từ RGB sang ảnh grayscale.\n",
    "    - **Downscaling**: Giảm kích thước của hình ảnh từ $32 \\times 32$ xuống $10 \\times 10$.\n",
    "    - **Histogram Generation**: Làm phẳng ảnh grayscale đã giảm kích thước $10 \\times 10$ thành một histogram với 100 bins.\n",
    "\n",
    "- **Điều Chỉnh Histogram**:\n",
    "    - **Zero-Avoidance**: Thêm một giá trị nhỏ $10^{-6}$ vào mỗi bin trong histogram để tránh các giá trị bằng 0.\n",
    "    - **Normalization**:\n",
    "        - Đối với mỗi cặp histogram (marginals), chia từng bin cho tổng khối lượng lớn nhất giữa hai histogram.\n",
    "        - Điều này dẫn đến một marginal có tổng khối lượng bằng 1, trong khi marginal còn lại có thể có tổng khối lượng nhỏ hơn 1.\n",
    "\n",
    "- **Tính Toán Ma Trận Cost**:\n",
    "    - **Squared Euclidean Distance**: Sử dụng khoảng cách Euclidean bình phương giữa các vị trí pixel làm metric chi phí $C$ cho việc vận chuyển.\n",
    "    - **Normalization**: Chuẩn hóa ma trận chi phí sao cho $\\|\\mathbf{C}\\|_{\\text{max}} = 1$.\n",
    "\n",
    "- **Thiết Lập Bài Toán Vận Chuyển**:\n",
    "    - **Transport Mass**: Đặt tổng khối lượng vận chuyển bằng 0.8 lần tổng khối lượng nhỏ nhất giữa hai marginals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sparsity(solution_matrix, threshold=1e-10):\n",
    "    \"\"\"\n",
    "    Hàm này đo lường sparsity của một ma trận, xem xét các phần tử có giá trị tuyệt đối\n",
    "    nhỏ hơn ngưỡng đã chỉ định là bằng 0.\n",
    "\n",
    "    Sparsity được định nghĩa là tỷ lệ các phần tử được xem là bằng 0 trong ma trận.\n",
    "\n",
    "    Tham số:\n",
    "    solution_matrix (np.ndarray): Ma trận cần đo lường sparsity.\n",
    "    threshold (float): Ngưỡng dưới đó các phần tử được coi là bằng 0 (mặc định là 1e-10).\n",
    "\n",
    "    Trả về:\n",
    "    float: Độ sparsity của ma trận, dưới dạng giá trị từ 0 đến 1.\n",
    "    \"\"\"\n",
    "    # Đếm số lượng phần tử được coi là bằng 0 (nhỏ hơn ngưỡng)\n",
    "    zero_elements = np.sum(np.abs(solution_matrix) < threshold)\n",
    "\n",
    "    # Tính tổng số phần tử trong ma trận\n",
    "    total_elements = solution_matrix.size\n",
    "\n",
    "    # Tính độ sparsity dưới dạng tỷ lệ của các phần tử được coi là bằng 0\n",
    "    sparsity = zero_elements / total_elements\n",
    "\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm giải bài toán Optimal Transport (OT) không có regularizer\n",
    "def sinkhornfix(a, b, C, epsilon, max_iter=1000, tol=1e-9, verbose=False):\n",
    "    n, m = C.shape\n",
    "    K = np.exp(-C / epsilon)\n",
    "    \n",
    "    u = np.ones(n)\n",
    "    v = np.ones(m)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        u_prev, v_prev = u.copy(), v.copy()\n",
    "        \n",
    "        # Update u and v using the Sinkhorn iteration\n",
    "        u = a / (np.dot(K, v) + 1e-12)  # Adding a small constant to avoid division by zero\n",
    "        v = b / (np.dot(K.T, u) + 1e-12)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Iteration:\", i)\n",
    "            print(\"u:\", u)\n",
    "            print(\"v:\", v)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(u - u_prev, 1) < tol and np.linalg.norm(v - v_prev, 1) < tol:\n",
    "            break\n",
    "    \n",
    "    P = np.outer(u, v) * K\n",
    "    return P\n",
    "\n",
    "def sinkhorn_log_domain(a, b, C, epsilon, max_iter=1000, tol=1e-9, verbose=False):\n",
    "    n, m = C.shape\n",
    "    \n",
    "    # Instead of using K directly, work with its logarithm\n",
    "    log_K = -C / epsilon\n",
    "    \n",
    "    # Initialize log_u and log_v\n",
    "    log_u = np.zeros(n)\n",
    "    log_v = np.zeros(m)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        log_u_prev, log_v_prev = log_u.copy(), log_v.copy()\n",
    "        \n",
    "        # Update log_u and log_v using log-domain Sinkhorn iterations\n",
    "        log_u = np.log(a) - np.log(np.exp(log_K + log_v).sum(axis=1) + 1e-12)\n",
    "        log_v = np.log(b) - np.log(np.exp(log_K.T + log_u).sum(axis=1) + 1e-12)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Iteration:\", i)\n",
    "            print(\"log_u:\", log_u)\n",
    "            print(\"log_v:\", log_v)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(log_u - log_u_prev, 1) < tol and np.linalg.norm(log_v - log_v_prev, 1) < tol:\n",
    "            break\n",
    "    \n",
    "    # Compute the transport plan in the original space\n",
    "    u = np.exp(log_u)\n",
    "    v = np.exp(log_v)\n",
    "    P = np.outer(u, v) * np.exp(log_K)\n",
    "    \n",
    "    return P\n",
    "\n",
    "def solve_ot(source_hist, target_hist, C):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) == source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) == target_hist.reshape(-1, 1).flatten(),\n",
    "    ]\n",
    "    # Định nghĩa hàm mục tiêu chỉ với cost matrix C mà không có regularizer\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(C, X)))\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return X.value\n",
    "\n",
    "# Hàm giải bài toán Optimal Transport (OT) có regularizer\n",
    "def solve_ot_quadratic_regularization(source_hist, target_hist, C, epsilon):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) == source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) == target_hist.reshape(-1, 1).flatten(),\n",
    "    ]\n",
    "\n",
    "    # Định nghĩa hàm mục tiêu chỉ với cost matrix C mà không có regularizer\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(C, X))+(epsilon / 2) * cp.norm(X, \"fro\") ** 2)\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return X.value\n",
    "\n",
    "# Hàm giải bài toán Optimal Transport (OT) không có regularizer\n",
    "def solve_pot_entropic_regularization(source_hist, target_hist, C, s, epsilon):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) <= source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) <= target_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X) == s,\n",
    "    ]\n",
    "\n",
    "    # Định nghĩa hàm mục tiêu chỉ với cost matrix C mà không có regularizer\n",
    "    def entropy(X):\n",
    "        tau=1e-10\n",
    "        return cp.sum(cp.entr(X + tau))  # Use the entr function which is DCP-compliant\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(C, X)) - (epsilon/2) * entropy(X))\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS, max_iters=3000, eps=1e-8, verbose=True)\n",
    "\n",
    "    return X.value\n",
    "\n",
    "def solve_pot_entropic_kl_regularization(source_hist, target_hist, C, s, epsilon):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) <= source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) <= target_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X) == s,\n",
    "    ]\n",
    "\n",
    "    # Define the cost term: sum(C * X)\n",
    "    cost_term = cp.sum(cp.multiply(C, X))\n",
    "\n",
    "    # Define the entropic regularization term: sum(X_ij * log(X_ij) - X_ij)\n",
    "    # Using cp.kl_div(X_ij, 1) which computes X_ij * log(X_ij) - X_ij for each element\n",
    "    entropy_term = cp.sum(cp.kl_div(X, np.ones((n, m))))\n",
    "\n",
    "    # Define the objective function: cost term + epsilon * entropy term\n",
    "    objective = cp.Minimize(cost_term + epsilon * entropy_term)\n",
    "\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS, max_iters=5000)\n",
    "\n",
    "    return X.value\n",
    "\n",
    "def solve_ot_entropic_regularization(source_hist, target_hist, C, epsilon):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) == source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) == target_hist.reshape(-1, 1).flatten(),\n",
    "    ]\n",
    "\n",
    "    # Định nghĩa hàm mục tiêu chỉ với cost matrix C mà không có regularizer\n",
    "    def entropy(X):\n",
    "        tau=1e-10\n",
    "        return cp.sum(cp.entr(X + tau))  # Use the entr function which is DCP-compliant\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(C, X)) - (epsilon/2) * entropy(X))\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=cp.SCS)\n",
    "\n",
    "    return X.value\n",
    "\n",
    "# Hàm giải POT với quadratic regularizer\n",
    "def solve_pot_quadratic_regularization(source_hist, target_hist, C, epsilon, s):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) <= source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) <= target_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X) == s,\n",
    "    ]\n",
    "\n",
    "    # Định nghĩa hàm mục tiêu với regularization quadratic\n",
    "    objective = cp.Minimize(cp.trace(C.T @ X) + (epsilon / 2) * cp.norm(X, \"fro\") ** 2)\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return X.value\n",
    "\n",
    "\n",
    "def solve_pot(source_hist, target_hist, C, s):\n",
    "    # Khai báo biến kế hoạch vận chuyển\n",
    "    X = cp.Variable(C.shape, nonneg=True)\n",
    "\n",
    "    # Định nghĩa các ràng buộc cho bài toán POT\n",
    "    constraints = [\n",
    "        cp.sum(X, axis=1) <= source_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X, axis=0) <= target_hist.reshape(-1, 1).flatten(),\n",
    "        cp.sum(X) == s,\n",
    "    ]\n",
    "\n",
    "    # Định nghĩa hàm mục tiêu chỉ với cost matrix C mà không có regularizer\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(C, X)))\n",
    "\n",
    "\n",
    "    # Định nghĩa và giải bài toán\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return X.value\n",
    "\n",
    "def round_heatmap(method_matrices, epsilon, lambda_param, threshold=1e-10):\n",
    "    \"\"\"\n",
    "    Plots heatmaps for the provided method matrices (solutions) and includes epsilon in the plot title.\n",
    "\n",
    "    :param threshold: The threshold value to discretize the solution matrices.\n",
    "    :param epsilon: The epsilon value to display in the plot title.\n",
    "    :param method_matrices: A dictionary where keys are method names and values are the corresponding solution matrices.\n",
    "    \"\"\"\n",
    "    # Discretize all input matrices (round them based on threshold)\n",
    "    rounded_matrices = {method: np.where(np.abs(matrix) < threshold, 0, 1) for method, matrix in method_matrices.items()}\n",
    "\n",
    "    num_matrices = len(rounded_matrices)\n",
    "    max_columns = min(3, num_matrices)  # Set the number of columns based on the number of matrices\n",
    "    num_rows = (num_matrices + max_columns - 1) // max_columns  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, max_columns, figsize=(6 * max_columns, 6 * num_rows))\n",
    "    axes = axes.flatten() if num_matrices > 1 else [axes]  # Flatten axes for easy iteration if more than one matrix\n",
    "\n",
    "    for idx, (method_name, rounded_matrix) in enumerate(rounded_matrices.items()):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Draw the heatmap for each method\n",
    "        sns.heatmap(rounded_matrix, cmap=sns.color_palette([\"white\", \"black\"], as_cmap=True), ax=ax, cbar=False)\n",
    "\n",
    "        # Set title and format the plot\n",
    "        ax.set_title(f\"Transport Plan {method_name}\\nEpsilon: {epsilon}, Lambda: {lambda_param} \\n Sparsity: {np.round(measure_sparsity(rounded_matrix), 4)}\", fontsize=16)\n",
    "        ax.set_xticks([])  # Remove x-axis ticks\n",
    "        ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "        # Add a box around the heatmap\n",
    "        for _, spine in ax.spines.items():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_linewidth(1.5)\n",
    "            spine.set_color('black')\n",
    "\n",
    "    # Hide unused axes\n",
    "    for idx in range(len(rounded_matrices), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"Lambdar_{lambda_param}.png\")  # Save the figure if necessary\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tạo phân phối Mixed Gaussian\n",
    "def generate_mixed_gaussian(n_samples, n_bins, mu1, sigma1, mu2, sigma2):\n",
    "    bernoulli = np.random.binomial(n=1, p=0.5, size=n_samples)\n",
    "    gaussian1 = np.random.normal(mu1, sigma1, n_samples)\n",
    "    gaussian2 = np.random.normal(mu2, sigma2, n_samples)\n",
    "    dist = gaussian1 * bernoulli + gaussian2 * (1 - bernoulli)\n",
    "\n",
    "    x = np.linspace(min(dist), max(dist), n_samples)\n",
    "    p, edges = np.histogram(dist, bins=n_bins, density=True)\n",
    "\n",
    "    pdf = 0.5 * (\n",
    "        1 / (sigma1 * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x - mu1) / sigma1) ** 2)\n",
    "    ) + 0.5 * (\n",
    "        1 / (sigma2 * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x - mu2) / sigma2) ** 2)\n",
    "    )\n",
    "\n",
    "    return dist, p, edges, x, pdf\n",
    "\n",
    "\n",
    "# Hàm tạo phân phối Poisson\n",
    "def generate_poisson(n_samples, n_bins, lambda_param):\n",
    "    dist = np.random.poisson(lambda_param, n_samples)\n",
    "\n",
    "    x = np.linspace(min(dist), max(dist), n_samples)\n",
    "    p, edges = np.histogram(dist, bins=n_bins, density=True)\n",
    "\n",
    "    pdf = np.exp(-lambda_param) * np.power(lambda_param, x) / factorial(x)\n",
    "\n",
    "    return dist, p, edges, x, pdf\n",
    "\n",
    "\n",
    "# Hàm tạo phân phối Beta\n",
    "def generate_beta(n_samples, n_bins, alpha, beta_param):\n",
    "    dist = np.random.beta(alpha, beta_param, n_samples)\n",
    "\n",
    "    p, edges = np.histogram(dist, bins=n_bins, density=True)\n",
    "\n",
    "    x = np.linspace(min(dist), max(dist), n_samples)\n",
    "    pdf = (x ** (alpha - 1) * (1 - x) ** (beta_param - 1)) / (\n",
    "        gamma(alpha) * gamma(beta_param) / gamma(alpha + beta_param)\n",
    "    )\n",
    "\n",
    "    return dist, p, edges, x, pdf\n",
    "\n",
    "\n",
    "# Hàm tạo phân phối Binomial\n",
    "def generate_binomial(n_samples, n_bins, n, p):\n",
    "    dist = np.random.binomial(n, p, n_samples)\n",
    "\n",
    "    x = np.linspace(min(dist), max(dist), n_samples)\n",
    "    p_dist, edges = np.histogram(dist, bins=n_bins, density=True)\n",
    "\n",
    "    pdf = (\n",
    "        (factorial(n) / (factorial(x) * factorial(n - x)))\n",
    "        * (p**x)\n",
    "        * ((1 - p) ** (n - x))\n",
    "    )\n",
    "\n",
    "    return dist, p_dist, edges, x, pdf\n",
    "\n",
    "\n",
    "# Hàm tạo phân phối Gamma\n",
    "def generate_gamma(n_samples, n_bins, shape, scale):\n",
    "    dist = np.random.gamma(shape, scale, n_samples)\n",
    "\n",
    "    x = np.linspace(min(dist), max(dist), n_samples)\n",
    "    p, edges = np.histogram(dist, bins=n_bins, density=True)\n",
    "\n",
    "    pdf = (x ** (shape - 1) * np.exp(-x / scale)) / (scale**shape * gamma(shape))\n",
    "\n",
    "    return dist, p, edges, x, pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Numerical experiments on Toy distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment between distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.2                                    \n",
      "===============================================================================\n",
      "(CVXPY) Sep 27 07:11:47 PM: Your problem has 10000 variables, 201 constraints, and 0 parameters.\n",
      "(CVXPY) Sep 27 07:11:47 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Sep 27 07:11:47 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Sep 27 07:11:47 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Sep 27 07:11:47 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Sep 27 07:11:47 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) Sep 27 07:11:47 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) Sep 27 07:11:47 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Sep 27 07:11:47 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Sep 27 07:11:47 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Sep 27 07:11:47 PM: Applying reduction SCS\n",
      "(CVXPY) Sep 27 07:11:47 PM: Finished problem compilation (took 3.021e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Sep 27 07:11:47 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.6 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 20000, constraints m: 40201\n",
      "cones: \t  z: primal zero / dual free vars: 1\n",
      "\t  l: linear vars: 10200\n",
      "\t  e: exp vars: 30000, dual exp vars: 0\n",
      "settings: eps_abs: 1.0e-08, eps_rel: 1.0e-08, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 3000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct-amd-qdldl\n",
      "\t  nnz(A): 60000, nnz(P): 0\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 1.81e+01  3.58e-01  3.14e+04 -1.81e+04  1.00e-01  4.08e-02 \n",
      "   250| 9.26e-02  2.68e-03  4.53e+01  1.24e+01  2.18e+00  2.06e+00 \n",
      "   500| 1.57e+16  1.58e+15  2.52e+19  1.33e+19  2.18e+00  3.49e+00 \n",
      "   525| 7.89e+09  1.08e+09  2.47e+19  1.35e+19  2.18e+00  3.52e+00 \n",
      "------------------------------------------------------------------\n",
      "status:  infeasible\n",
      "timings: total: 3.52e+00s = setup: 2.87e-02s + solve: 3.49e+00s\n",
      "\t lin-sys: 3.61e-01s, cones: 2.96e+00s, accel: 4.12e-02s\n",
      "------------------------------------------------------------------\n",
      "objective = inf\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Sep 27 07:11:51 PM: Problem status: infeasible\n",
      "(CVXPY) Sep 27 07:11:51 PM: Optimal value: inf\n",
      "(CVXPY) Sep 27 07:11:51 PM: Compilation took 3.021e-02 seconds\n",
      "(CVXPY) Sep 27 07:11:51 PM: Solver (including time spent in interface) took 3.525e+00 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m runtime_epot \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Measure sparsity of the solution matrix\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m sparsity_epot \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_epot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[0;32m     95\u001b[0m runtimes[(dist_a_name, dist_b_name)] \u001b[38;5;241m=\u001b[39m [runtime_qpot, runtime_epot]\n",
      "Cell \u001b[1;32mIn [2], line 16\u001b[0m, in \u001b[0;36mmeasure_sparsity\u001b[1;34m(solution_matrix, threshold)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mHàm này đo lường sparsity của một ma trận, xem xét các phần tử có giá trị tuyệt đối\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mnhỏ hơn ngưỡng đã chỉ định là bằng 0.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mfloat: Độ sparsity của ma trận, dưới dạng giá trị từ 0 đến 1.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Đếm số lượng phần tử được coi là bằng 0 (nhỏ hơn ngưỡng)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m zero_elements \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution_matrix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m threshold)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Tính tổng số phần tử trong ma trận\u001b[39;00m\n\u001b[0;32m     19\u001b[0m total_elements \u001b[38;5;241m=\u001b[39m solution_matrix\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for abs(): 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Define the fixed parameters for the experiment\n",
    "n_bins = 100\n",
    "n_samples = 100000\n",
    "mu1, sigma1 = 1, 2\n",
    "mu2, sigma2 = 10, 1.5\n",
    "epsilon = 10\n",
    "lambda_param = 0.99\n",
    "\n",
    "# Define the distribution pairs\n",
    "distribution_names = [\"Mixed Gaussian\", \"Gamma\", \"Beta\", \"Poisson\", \"Binomial\"]\n",
    "\n",
    "# Store results\n",
    "runtimes = {}\n",
    "sparsities = {}\n",
    "\n",
    "# Iterate through all possible pairs of distributions\n",
    "for i, dist_a_name in enumerate(distribution_names):\n",
    "    for j, dist_b_name in enumerate(distribution_names):\n",
    "        if dist_a_name == dist_b_name:\n",
    "            continue\n",
    "        # Generate the first distribution based on the name\n",
    "        if dist_a_name == \"Mixed Gaussian\":\n",
    "            dist_a, p_a, edges_a, x_a, pdf_a = generate_mixed_gaussian(\n",
    "                n_samples, n_bins, mu1, sigma1, mu2, sigma2\n",
    "            )\n",
    "        elif dist_a_name == \"Gamma\":\n",
    "            shape_a, scale_a = 7, 1\n",
    "            dist_a, p_a, edges_a, x_a, pdf_a = generate_gamma(\n",
    "                n_samples, n_bins, shape_a, scale_a\n",
    "            )\n",
    "        elif dist_a_name == \"Beta\":\n",
    "            alpha_a, beta_a = 2, 2\n",
    "            dist_a, p_a, edges_a, x_a, pdf_a = generate_beta(\n",
    "                n_samples, n_bins, alpha_a, beta_a\n",
    "            )\n",
    "        elif dist_a_name == \"Poisson\":\n",
    "            lambda_a = 5\n",
    "            dist_a, p_a, edges_a, x_a, pdf_a = generate_poisson(n_samples, n_bins, lambda_a)\n",
    "        elif dist_a_name == \"Binomial\":\n",
    "            n_a, p_binom_a = 10, 0.4\n",
    "            dist_a, p_a, edges_a, x_a, pdf_a = generate_binomial(\n",
    "                n_samples, n_bins, n_a, p_binom_a\n",
    "            )\n",
    "\n",
    "        # Generate the second distribution based on the current pair\n",
    "        if dist_b_name == \"Mixed Gaussian\":\n",
    "            dist_b, p_b, edges_b, x_b, pdf_b = generate_mixed_gaussian(\n",
    "                n_samples, n_bins, mu1, sigma1, mu2, sigma2\n",
    "            )\n",
    "        elif dist_b_name == \"Gamma\":\n",
    "            shape_b, scale_b = 7, 1\n",
    "            dist_b, p_b, edges_b, x_b, pdf_b = generate_gamma(\n",
    "                n_samples, n_bins, shape_b, scale_b\n",
    "            )\n",
    "        elif dist_b_name == \"Beta\":\n",
    "            alpha_b, beta_b = 2, 2\n",
    "            dist_b, p_b, edges_b, x_b, pdf_b = generate_beta(\n",
    "                n_samples, n_bins, alpha_b, beta_b\n",
    "            )\n",
    "        elif dist_b_name == \"Poisson\":\n",
    "            lambda_b = 5\n",
    "            dist_b, p_b, edges_b, x_b, pdf_b = generate_poisson(n_samples, n_bins, lambda_b)\n",
    "        elif dist_b_name == \"Binomial\":\n",
    "            n_b, p_binom_b = 10, 0.4\n",
    "            dist_b, p_b, edges_b, x_b, pdf_b = generate_binomial(\n",
    "                n_samples, n_bins, n_b, p_binom_b\n",
    "            )\n",
    "\n",
    "        # Normalize distributions\n",
    "        p_a = p_a / np.sum(p_a)\n",
    "        p_b = p_b / np.sum(p_b)\n",
    "        s = lambda_param * min(p_a.sum(), p_b.sum())\n",
    "\n",
    "        # Compute cost matrix using L2 norm\n",
    "        C = (edges_a[:-1].reshape(-1, 1) - edges_b[:-1].reshape(1, -1)) ** 2\n",
    "        C = C / np.max(C)\n",
    "\n",
    "        # Solve the POT problem using QPOT\n",
    "        start_time = time.time()\n",
    "        X_qpot = solve_pot_quadratic_regularization(p_a, p_b, C, epsilon, s)\n",
    "        runtime_qpot = time.time() - start_time\n",
    "\n",
    "        # Measure sparsity of the solution matrix\n",
    "        sparsity_qpot = measure_sparsity(X_qpot)\n",
    "\n",
    "        # Solve the POT problem using EPOT\n",
    "        start_time = time.time()\n",
    "        X_epot = solve_pot_entropic_regularization(p_a, p_b, C, epsilon, s)\n",
    "        runtime_epot = time.time() - start_time\n",
    "\n",
    "        # Measure sparsity of the solution matrix\n",
    "        sparsity_epot = measure_sparsity(X_epot)\n",
    "\n",
    "        # Store results\n",
    "        if np.abs(sparsity_qpot - sparsity_epot) > 0.1:\n",
    "            runtimes[(dist_a_name, dist_b_name)] = [runtime_qpot, runtime_epot]\n",
    "            sparsities[(dist_a_name, dist_b_name)] = [sparsity_qpot, sparsity_epot]\n",
    "\n",
    "\n",
    "figure_path = 'toy_distribution_experiment'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "# Extract data from the sparsities dictionary\n",
    "dist_pairs = list(sparsities.keys())\n",
    "qpot_sparsities = [sparsities[pair][0] for pair in dist_pairs]  # Sparsities for QPOT\n",
    "epot_sparsities = [sparsities[pair][1] for pair in dist_pairs]  # Sparsities for EPOT\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(dist_pairs))  # Number of distribution pairs\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for QPOT and EPOT sparsities\n",
    "bars_qpot = ax.bar(x - width/2, qpot_sparsities, width, label='QPOT Sparsity', color='b')\n",
    "bars_epot = ax.bar(x + width/2, epot_sparsities, width, label='EPOT Sparsity', color='r')\n",
    "\n",
    "# Add labels, title, and custom ticks\n",
    "ax.set_xlabel('Distribution Pairs', fontsize=14)\n",
    "ax.set_ylabel('Sparsity', fontsize=14)\n",
    "ax.set_title('Comparison of Sparsity: QPOT vs EPOT', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{pair[0]} vs {pair[1]}' for pair in dist_pairs], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, 'sparsity_pairs of distribution.png'))\n",
    "plt.show()\n",
    "\n",
    "qpot_runtimes = [runtimes[pair][0] for pair in dist_pairs]  # Sparsities for QPOT\n",
    "epot_runtimes = [runtimes[pair][1] for pair in dist_pairs]  # Sparsities for EPOT\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(dist_pairs))  # Number of distribution pairs\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for QPOT and EPOT sparsities\n",
    "bars_qpot = ax.bar(x - width/2, qpot_runtimes, width, label='QPOT Sparsity', color='b')\n",
    "bars_epot = ax.bar(x + width/2, epot_runtimes, width, label='EPOT Sparsity', color='r')\n",
    "\n",
    "# Add labels, title, and custom ticks\n",
    "ax.set_xlabel('Distribution Pairs', fontsize=14)\n",
    "ax.set_ylabel('Runtime', fontsize=14)\n",
    "ax.set_title('Comparison of Runtime: QPOT vs EPOT', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{pair[0]} vs {pair[1]}' for pair in dist_pairs], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, 'runtime_pairs of distribution.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment on multiple epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fixed parameters for the experiment\n",
    "n_bins = 100\n",
    "n_samples = 100000\n",
    "mu1, sigma1 = 1, 2\n",
    "mu2, sigma2 = 10, 1.5\n",
    "epsilon = 10\n",
    "lambda_param = 0.99\n",
    "\n",
    "epsilon_list = [2**(-i) for i in range(0, 51)]\n",
    "\n",
    "dist_a, p_a, edges_a, x_a, pdf_a = generate_mixed_gaussian(\n",
    "                n_samples, n_bins, mu1, sigma1, mu2, sigma2\n",
    "            )\n",
    "\n",
    "dist_b, p_b, edges_b, x_b, pdf_b = generate_gamma(\n",
    "                n_samples, n_bins, 7, 1\n",
    "            )\n",
    "\n",
    "# Normalize distributions\n",
    "p_a = p_a / np.sum(p_a)\n",
    "p_b = p_b / np.sum(p_b)\n",
    "s = lambda_param * min(p_a.sum(), p_b.sum())\n",
    "\n",
    "# Compute cost matrix using L2 norm\n",
    "C = (edges_a[:-1].reshape(-1, 1) - edges_b[:-1].reshape(1, -1)) ** 2\n",
    "C = C / np.max(C)\n",
    "\n",
    "sparsities = {'QPOT' : [], 'EPOT': []}\n",
    "runtimes = {'QPOT' : [], 'EPOT': []}\n",
    "for epsilon in epsilon_list:\n",
    "    # Solve the POT problem using QPOT\n",
    "    start_time = time.time()\n",
    "    X_qpot = solve_pot_quadratic_regularization(p_a, p_b, C, epsilon, s)\n",
    "    runtime_qpot = time.time() - start_time\n",
    "\n",
    "    # Measure sparsity of the solution matrix\n",
    "    sparsity_qpot = measure_sparsity(X_qpot)\n",
    "    sparsities['QPOT'].append(sparsity_qpot)\n",
    "    runtimes['QPOT'].append(runtime_qpot)\n",
    "\n",
    "    # Solve the POT problem using EPOT\n",
    "    start_time = time.time()\n",
    "    X_epot = solve_pot_entropic_regularization(p_a, p_b, C, epsilon, s)\n",
    "    runtime_epot = time.time() - start_time\n",
    "\n",
    "    # Measure sparsity of the solution matrix\n",
    "    sparsity_epot = measure_sparsity(X_epot)\n",
    "    sparsities['EPOT'].append(sparsity_epot)\n",
    "    runtimes['EPOT'].append(runtime_epot)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "# Plot with improved line styles and colors\n",
    "plt.plot(x, sparsities[\"QPOT\"], label=\"QPOT\", color='#1f77b4', linewidth=1.5, linestyle='-')\n",
    "plt.plot(x, sparsities[\"EPOT\"], label='EPOT', color='r', linewidth=1.5, linestyle='--')\n",
    "# plt.plot(x, sparsity_cifar[\"KLPOT\"], label='KLPOT', color='blue', linewidth=1.5, linestyle='-')\n",
    "# plt.plot(x, sparsity_cifar[\"QOT\"], label='QOT', color='#ff7f0e', linewidth=1.5, linestyle='--')\n",
    "# plt.plot(x, sparsity_cifar[\"EOT\"], label='EOT', color='#2ca02c', linewidth=1.5, linestyle='-.')\n",
    "# plt.plot(x, sparsity_cifar[\"EOTL\"], label='EOT Library', color='m', linewidth=1.5, linestyle='-.')\n",
    "# plt.plot(x, sparsity_cifar[\"LEOT\"], label='Log EOT', color='r', linewidth=1.5, linestyle='-.')\n",
    "\n",
    "# Draw horizontal lines for OT and POT\n",
    "#plt.hlines(y=sparsity_cifar[\"OT\"], xmin=2**(0), xmax=2**(-51), color='k', linewidth=1.5, linestyle='--', label='OT')\n",
    "#plt.hlines(y=sparsity_cifar[\"POT\"], xmin=2**(0), xmax=2**(-51), color='k', linewidth=1.5, linestyle='-', label='POT')\n",
    "\n",
    "# Set title and labels with improved font settings\n",
    "plt.title('Sparsity of numerical Experiment on Mixed Gaussian and Gamma with λ = ' + str(lambda_param), fontsize=25, fontweight='bold')\n",
    "plt.xlabel(r'$\\varepsilon$ coefficient', fontsize=22, fontdict={'family': 'serif', 'weight': 'bold'})\n",
    "plt.ylabel('Sparsity', fontsize=22, fontdict={'family': 'serif', 'weight': 'bold'})\n",
    "\n",
    "# Add a grid with a specific style\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=-45)\n",
    "\n",
    "# Adjust tick parameters\n",
    "plt.xscale(\"log\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.gca().invert_xaxis() \n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'sparsity_multiple_epsilon_lambda{lambda_param}.png'))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "# Plot with improved line styles and colors\n",
    "plt.plot(x, runtimes[\"QPOT\"], label=\"QPOT\", color='#1f77b4', linewidth=1.5, linestyle='-')\n",
    "plt.plot(x, runtimes[\"EPOT\"], label='EPOT', color='r', linewidth=1.5, linestyle='--')\n",
    "# plt.plot(x, sparsity_cifar[\"KLPOT\"], label='KLPOT', color='blue', linewidth=1.5, linestyle='-')\n",
    "# plt.plot(x, sparsity_cifar[\"QOT\"], label='QOT', color='#ff7f0e', linewidth=1.5, linestyle='--')\n",
    "# plt.plot(x, sparsity_cifar[\"EOT\"], label='EOT', color='#2ca02c', linewidth=1.5, linestyle='-.')\n",
    "# plt.plot(x, sparsity_cifar[\"EOTL\"], label='EOT Library', color='m', linewidth=1.5, linestyle='-.')\n",
    "# plt.plot(x, sparsity_cifar[\"LEOT\"], label='Log EOT', color='r', linewidth=1.5, linestyle='-.')\n",
    "\n",
    "# Draw horizontal lines for OT and POT\n",
    "#plt.hlines(y=sparsity_cifar[\"OT\"], xmin=2**(0), xmax=2**(-51), color='k', linewidth=1.5, linestyle='--', label='OT')\n",
    "#plt.hlines(y=sparsity_cifar[\"POT\"], xmin=2**(0), xmax=2**(-51), color='k', linewidth=1.5, linestyle='-', label='POT')\n",
    "\n",
    "# Set title and labels with improved font settings\n",
    "plt.title('Runtimes of numerical Experiment on Mixed Gaussian and Gamma with λ = ' + str(lambda_param), fontsize=25, fontweight='bold')\n",
    "plt.xlabel(r'$\\varepsilon$ coefficient', fontsize=22, fontdict={'family': 'serif', 'weight': 'bold'})\n",
    "plt.ylabel('Runtimes', fontsize=22, fontdict={'family': 'serif', 'weight': 'bold'})\n",
    "\n",
    "# Add a grid with a specific style\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=-45)\n",
    "\n",
    "# Adjust tick parameters\n",
    "plt.xscale(\"log\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.gca().invert_xaxis() \n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'sparsity_multiple_epsilon_lambda{lambda_param}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment on multiple lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "n_samples = 100000\n",
    "mu1, sigma1 = 1, 2\n",
    "mu2, sigma2 = 10, 1.5\n",
    "epsilon = 10\n",
    "\n",
    "runtimes = {}\n",
    "sparsities = {}\n",
    "\n",
    "lambda_list = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "dist_a, p_a, edges_a, x_a, pdf_a = generate_mixed_gaussian(\n",
    "                n_samples, n_bins, mu1, sigma1, mu2, sigma2\n",
    "            )\n",
    "\n",
    "dist_b, p_b, edges_b, x_b, pdf_b = generate_gamma(\n",
    "                n_samples, n_bins, 7, 1\n",
    "            )\n",
    "\n",
    "# Normalize distributions\n",
    "p_a = p_a / np.sum(p_a)\n",
    "p_b = p_b / np.sum(p_b)\n",
    "\n",
    "# Compute cost matrix using L2 norm\n",
    "C = (edges_a[:-1].reshape(-1, 1) - edges_b[:-1].reshape(1, -1)) ** 2\n",
    "C = C / np.max(C)\n",
    "\n",
    "sparsities = {'QPOT' : [], 'EPOT': []}\n",
    "runtimes = {'QPOT' : [], 'EPOT': []}\n",
    "for lambda_param in lambda_list:\n",
    "    s = lambda_param * min(p_a.sum(), p_b.sum())\n",
    "    # Solve the POT problem using QPOT\n",
    "    start_time = time.time()\n",
    "    X_qpot = solve_pot_quadratic_regularization(p_a, p_b, C, epsilon, s)\n",
    "    runtime_qpot = time.time() - start_time\n",
    "\n",
    "    # Measure sparsity of the solution matrix\n",
    "    sparsity_qpot = measure_sparsity(X_qpot)\n",
    "\n",
    "    # Solve the POT problem using EPOT\n",
    "    start_time = time.time()\n",
    "    X_epot = solve_pot_entropic_regularization(p_a, p_b, C, epsilon, s)\n",
    "    runtime_epot = time.time() - start_time\n",
    "\n",
    "    # Measure sparsity of the solution matrix\n",
    "    sparsity_epot = measure_sparsity(X_epot)\n",
    "    \n",
    "    sparsities[lambda_param] = (sparsity_qpot, sparsity_epot)\n",
    "    runtimes[lambda_param] = (runtime_qpot, runtime_epot)\n",
    "    \n",
    "# Extract data from the sparsities dictionary\n",
    "qpot_sparsities = [sparsities[lambda_param][0] for lambda_param in lambda_list]  # Sparsities for QPOT\n",
    "epot_sparsities = [sparsities[lambda_param][1] for lambda_param in lambda_list]  # Sparsities for EPOT\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(lambda_list))  # Number of distribution pairs\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for QPOT and EPOT sparsities\n",
    "bars_qpot = ax.bar(x - width/2, qpot_sparsities, width, label='QPOT Sparsity', color='b')\n",
    "bars_epot = ax.bar(x + width/2, epot_sparsities, width, label='EPOT Sparsity', color='r')\n",
    "\n",
    "# Add labels, title, and custom ticks\n",
    "ax.set_xlabel('Lambda', fontsize=14)\n",
    "ax.set_ylabel('Sparsity', fontsize=14)\n",
    "ax.set_title('Comparison of Sparsity on multiple Lambda: QPOT vs EPOT', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{lambda_param}' for lambda_param in lambda_list], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'sparsity_multiple_lambda_lambda{lambda_param}.png'))\n",
    "plt.show()\n",
    "\n",
    "qpot_runtimes = [sparsities[lambda_param][0] for lambda_param in lambda_list]  # Sparsities for QPOT\n",
    "epot_runtimes = [sparsities[lambda_param][1] for lambda_param in lambda_list]  # Sparsities for EPOT\n",
    "\n",
    "# Define the positions for the bars\n",
    "x = np.arange(len(lambda_list))  # Number of distribution pairs\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot bars for QPOT and EPOT sparsities\n",
    "bars_qpot = ax.bar(x - width/2, qpot_runtimes, width, label='QPOT Sparsity', color='b')\n",
    "bars_epot = ax.bar(x + width/2, epot_runtimes, width, label='EPOT Sparsity', color='r')\n",
    "\n",
    "# Add labels, title, and custom ticks\n",
    "ax.set_xlabel('Lambda', fontsize=14)\n",
    "ax.set_ylabel('Runtime', fontsize=14)\n",
    "ax.set_title('Comparison of Runtime on multiple Lambda: QPOT vs EPOT', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{lambda_param}' for lambda_param in lambda_list], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figure_path, f'runtime_multiple_lambda_lambda{lambda_param}.png'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
